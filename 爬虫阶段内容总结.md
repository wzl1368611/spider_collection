## 爬虫内容总结
- 用git提交项目到github的方法
    ```
    git init 
    git add .
    git commit -m 'first commit'
    git remote add origin https://...
    git push -u origin master # (第一次提交到远程库中)
    git push origin master # (之后提交到远程库中)
    git config http.postBuffer 52428800
    ```
- git的设置
    ```
    git config --global core.autocrlf false
    ```
- 项目开发流程
  - 开发一个软件项目的流程
    ```
    需求分析-->概要设计-->项目规划-->详细设计-->编码测试-->项目功能测试-->
    调试完善-->项目发布-->后期维护
    ```
- mysql添加外键约束
  1. 首先要创建一个字段：
  ```
  alter table 表名 add 字段名 字段类型  
  ```
  2. 再添加外键约束
  ```python
  '''
    alter table 需加外键的表 add constraint 外键名 foreign key(需加外键表的字段名) references 关联表名(关联字段名)
    注意：字段名不能重复
  ''' 
  ```
- 给表添加外键实例
  ```
    create table tb1（
    id INT PRIMARY KEY AUTO_INCREMENT,
    classname VARCHAR(20) NOT NULL
  ）;
  create table tb2(
    id INT PRIMARY KEY AUTO_INCREMENT,
    username VARCHAR(20) NOT NULL,
    classid INT,
    FOREIGN KEY (classid) REFERENCES tb1(id) ON DELETE CASCADE ON UPDATE CASCADE
  );
  ALTER TABLE tb3 ADD CONSTRAINT T_C FOREIGN KEY (classid) REFERENCES tb1(id);
  ALTER TABLE tb3 ADD CONSTRAINT T_C FOREIGN KEY (classid) REFERENCES tb1(id);
  删除外键：alter table emp drop foreign key 外键名; 
  ```
- 重点知识
  ```
  '''
  eval(str)
  BaseDir = os.path.dirname(os.path.dirname(os.path.abspath()))
  关于javascript内容:
    window.scrollTo(0,document.body.scrollHeight) 
    window.location.replace('https://www.runoob.com');
    window.location.href='xxx'; 
  '''  
  ```
- 关于uuid
  - uuid
  - hashlib.md5()
- 项目部署：以具体的前后端分离项目为例子
  1. 代码下载
  2. 修改配置
  3. 本地运行
  4. 前后端项目的编译、构建、打包
  5. 最后部署到服务器软件中 ——一系列完整的步骤
  - 环境准备：linux系统环境 软件环境 工具 基础设施
    - 基础设置：数据库mysql 缓存redis
    - 后端要装的环境：jdk maven tomcat nginx
    - 前端主机要装的环境：nginx mysql redis
    - 后端主机：
    - 已经安装的顺序：git jdk maven mysql tomcat nginx redis python3
    - mysql首次登陆密码：BK*gHrSv_4F#  (先保存，后面进mysql更改密码)
- git相关
  ```
    git commit -a -m "提交本地版本" 
    再拉取github上面的最新版本
    git fetch origin 
    然后合并到本地分支，如有冲突可在IDE中查看文件解决
    git merge -m "解决与上游版本不一致问题" origin/master
    push到github
    git push origin master

  ```
- nginx教程；
  [参考一](https://www.bookstack.cn/read/dunwu-nginx-tutorial/docs-README.md)
  [参考二](https://xuexb.github.io/learn-nginx/)
- django教程；
  [django一](https://www.cnblogs.com/liuhui0308/p/12189658.html)
- 阶段todo(待完成的任务):
  ```
  flask django scrapy redis rabbitmq和PRC  docker nginx elasticsearch
  golang
  ```
### 在服务器环境运行爬虫
- 创建环境
    ```
    (/root/fbsProject): virtualenv /root/venvs/fbsProject -p python3
	(/root/fbsProject): source /root/venvs/fbsProject/bin/activate
		  	            pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple 

    ```
- mongodb操作:
    ```
        更新：db.student.update({name:{$regex:'北'}},{$set:{name:'小北',age:17}})
        查找：db.student.find().pretty()
        插入：db.student.insert({name:'小北',age:19})
            db.student.save({name:'小北',age:19})
        show dbs
        show collections
        删除：db.student.drop()
    ```
- docker 运行redis
    ```
        docker pull redis
        docker run -dit --name redis_spider0 -p 6378:6379 redis
        docker exec -it redis_spider0 bash
    ```
    - 删除索引：
   ```
       import requests 
       requests.delete('requests.delete('http://192.168.18.101:9200/dushu')
   ```
    - 清空redis：
    ```
        from redis import Redis
        rd = Redis('192.168.18.101','6378')
        rd.lpush('gx_start_urls','https://www.dushu.com/guoxue')
        rd.keys('*')
        rd.flushall() # 清空redis
    ```
- 爬虫部署
    ```
        nohup scrapyd &	
	
        scrapyd-deploy 100 -p dushu02_redis
        curl http://localhost:6800/schedule.json -d project=default -d spider=somespider
        data={}
        data['project']='dushu02_redis'
        data['spider']='guoxue'
        url = 'http://192.168.18.101:6800/schedule.json'
        rep = requests.post(url,data)
        
        data['job']='03bc44e03b9811eb8d13000c29ef33a6'
        
    ```
  - 关闭scrapyd
    ```
        查找进程并删除
        ps -ef|grep nohup
        ps -ef|grep scrapy
        kill -9 13440 
    ```
  - docker部署
    - 3.2.1 commit方式
        ```
            docker commit -m '消息' -a 'disen作者' front-manage disen/project:1.0
            front-manage 容器名
            disen/project:1.0 打包的镜像名
            通过dockedr images查看本地镜像库
            
        ```
    - 3.2.2 编写Dockerfile文件
        ```
           FROM 192.168.18.101:5000/ubuntu:latest
            MAINTAINER wzl 1793268783@qq.com
            ADD . /usr/src
            WORKDIR /usr/src
            RUN pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple
            RUN chmod +x run.sh
            CMD /usr/src/run.sh 
        ```
    - 3.2.3 编写shell脚本
        ```shell script
            #!/bin/bash
            cd /usr/src
            scrapy crawl guoxue
        ```
    - 3.2.4 构建镜像
    docker build -t dushu:1.0 .
    - 3.2.5 启动爬虫
    docker run -dit --name server2 dushu:1.0
    - 出错删除命令
        ```
            docker rm spider_dushu	(删除容器命令)
            docker rmi dushu:1.0	(删除镜像)    
        ```
    - 运行容器
        ```
            (dushu_spider):	docker run -dit --name dushu_spider -v /root/dushu_spider02:/usr/src dushu:1.0 
                            查看信息
                            docker logs spider_dushu
                            删除文件
                            rm dushu.log
            
        ```
- 安装docker 
    ```
    duso apt install docker.io -y
    ```
- 虚拟机下安装ubuntu
  - 设置ubuntu下的/etc/netplan/00XXX.yuml文件 
    ```
        network:
          version: 2
          renderer: networkd
          ethernets:
            ens33:	#（用ifconfig -a查看所有端口，更改存在的接口）
              dhcp4: yes 	(dhcp4要设置为yes,dhcp6设置为no)
              addresses:
                - 192.168.121.199/24 	#（第四位数字199必须小于255，并且/后为24，其他格式不同）
              gateway4: 192.168.121.1
              nameservers:	#（特别注意空格和缩进，一有错误会报错）
                  addresses: [8.8.8.8, 1.1.1.1]
        正确的格式如下：
        # This is the network config written by 'subiquity'
        network:
            ethernets: 
                ens33:
                    addresses: [192.168.18.158/24, ]
                    dhcp4: yes
                    dhcp6: no
                    gateway4: 192.168.18.2
                    nameservers:
                            addresses: [114.114.114.114, 8.8.8.8]
            version: 2

    ```
  - 查看ubuntu版本信息
    ```
        lsb_release -a
	    cat /etc/issue 
        ubuntu查看ip:
	    ip a 
    ```
  - root用于远程连接设置
    ```
        sudo passwd root #(创建用户 密码)
        sudo vim /etc/ssh/ssh_config # (使用超级用户编辑 加入一行 PermitRootLogin yes)
        sudo service sshd  restart # (或者ssh，重启服务)
    ```
  - 免密登录设置
    ```
        scp id_rsa.pub wzl@192.168.18.158:~/	#(上传文件命令)
        sudo su
        cd /root
        mkdir .ssh
        cd .ssh
        cat id_rsa.pub >> .ssh/authorized_keys	#(追加命令，将内容追加到authorized_keys)
    ```
  - 生成公钥秘钥
    ```
        ssh-keygen    
    ```
  - docker命令
    ```
        sudo docker logs es(容器名) # 查看信息
        docker stop id #停止已启动的服务
        docker start id
        docker logs id # (/name)
        docker ps -a
        docker ps -l
        docker ps 
    ```
  - docker下部署splash服务
    ```
        docker pull scrapinghub/splash
        docker run -dit --name splash-server -p 5052:5023 -p 8050:8050 -p 8051:8051 scrapinghub/splash
        一般只用http模式，启动一个8050（http）就好，也可指定8051（https）和5023（talnet） 
    ```
  - docker 搭建shell仓库
    1. docker pull registry
    2. 编辑vi /etc/docker/daemon.json
        ```json
        {
          "registry-mirrors": [
            "https://hub-mirror.c.163.com",
            "https://mirror.baidubce.com"
          ],
          "insecure-registries":["192.168.18.158:5000"]
        }
        ```
    3. 重启进程
        ```
            $ sudo systemctl daemon-reload
	        $ sudo systemctl restart docker
        ```
    4. 重启私有库
        ```
            docker ps
            docker start private_docker_registry
            docker ps
           
        ```
    5. 重新打标签
        ```
            docker images
            docker tag scrapyinghub/splash 192.168.18.158:5000/splash
            docker images
       ```
    6. 推镜像到私有库
        ```
            docker push 192.168.18.158:5000/splash
       ```
    7. 其他用户拉取镜像
      - ssh 连接登录
	  - 设置vi /etc/docker/daemon.json
	    ```
           {
              "registry-mirrors": [
                "https://hub-mirror.c.163.com",
                "https://mirror.baidubce.com"
              ],
              "insecure-registries":["192.168.18.158:5000"]
            }	        
        ```
    8. 其他用户拉取镜像
        ```
            docker pull 192.168.18.158:5000/splash
        ```
    - 解释
        ```
          systemctl daemon-reload	#(systemctl 系统控制面板)
          systemctl restart docker
        ```
  - 在crontab中运行爬虫: 
    - vi /etc/runspider.sh
        ```shell script
            #!/bin/bash
            docker start dushu_spider
        ```
    - 操作
        ```
            - 加权限：
            chmox +x runspider.sh
            ln -s /root/runspider.sh /usr/bin/run_dushu 	#(做个软连接)
            任意位置启动程序:
            run_dushu
        ```
    - Dockerfile文件编写
        ```Dockerfile
        FROM 192.168.18.101:5000/ubuntu:latest
        MAINTAINER wzl 1793268783@qq.com
        ADD . /usr/src
        VOLUME /usr/src
        WORKDIR /usr/src
        RUN pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple
        RUN chmod +x run.sh
        CMD /usr/src/run.sh
    
        ```
    - 编辑定时任务：vi /root/dushu.cron
        ```
        * * * * * run_dushu
        每半小时执行一次run_dushu命令：即
        30 * * * * run_dushu
        添加定时任务：
        crontab dushu.cron
        
        格式：分钟 小时 天 月份 星期
        查看定时任务命令：crontab -l
       ```
  - 几个参考文档地址
    - [linux文档地址](https://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/crontab.html)
    - [docker文档地址](https://yeasy.gitbook.io/docker_practice/install/mirror)
  - 关于splash的http api(渲染使用) 
      ```
        curl http://localhost:8050/render.html?url=http://jd.com     
      ```
  - docker elasticsearch命令：
    ```
        http://192.168.18.158:9200/_all/_search
    ```
  - ubuntu操作命令：软链接
    ```
        ln -s /usr/local/python3/bin/pip3 /usr/bin/pip
    ```
  - Dockerfile规范
    ```
        FROM 
        WORKDIR
        COPY
        RUN
        CMD
        EXPOSE
        VOLUME
        ENV(环境变量)
        ARG(构建参数，变量)
        LABEL key='value' (元素)
        ONBUILD  ENV C=100

    ```
  - TODO
  ```
    做好输出，归纳总结，写好博客md，整理之前学过的一个礼拜的知识
	接下来学习的内容linux
	crm
  ```
    
       

  
    
    